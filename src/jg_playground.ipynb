{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def get_model_configs() -> List[Dict[str, any]]:\n",
    "    \"\"\"Define all model configurations based on the complete grid.\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"model_name\": \"google/gemma-2b\",\n",
    "            \"model_short\": \"gemma-2b\",\n",
    "            \"layers\": [\"6\", \"12\", \"17\"],\n",
    "            \"widths\": [\"16k\"],  # 2^14\n",
    "            \"datasets\": [\n",
    "                (\"Anthropic/election_questions\", \"test\"),\n",
    "                (\"textdetox/multilingual_toxicity_dataset\", \"en\"),\n",
    "                (\"AIM-Harvard/reject_prompts\", \"train\"),\n",
    "                (\"jackhhao/jailbreak-classification\", \"test\"),\n",
    "                (\"sorry-bench/sorry-bench-202406\", \"train\"),\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"model_name\": \"google/gemma-2-2b\",\n",
    "            \"model_short\": \"gemma-2-2b\",\n",
    "            \"layers\": [\"5\", \"12\", \"19\"],\n",
    "            \"widths\": [\"16k\", \"65k\", \"1m\"],  # 2^14, 2^16, 2^20\n",
    "            \"datasets\": [\n",
    "                (\"Anthropic/election_questions\", \"test\"),\n",
    "                (\"textdetox/multilingual_toxicity_dataset\", \"en\"),\n",
    "                (\"AIM-Harvard/reject_prompts\", \"train\"),\n",
    "                (\"jackhhao/jailbreak-classification\", \"test\"),\n",
    "                (\"sorry-bench/sorry-bench-202406\", \"train\"),\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"model_name\": \"google/gemma-2-9b\",\n",
    "            \"model_short\": \"gemma-2-9b\",\n",
    "            \"layers\": [\"9\", \"20\", \"31\"],\n",
    "            \"widths\": [\"16k\", \"131k\", \"1m\"],  # 2^14, 2^17, 2^20\n",
    "            \"datasets\": [\n",
    "                (\"Anthropic/election_questions\", \"test\"),\n",
    "                (\"textdetox/multilingual_toxicity_dataset\", \"en\"),\n",
    "                (\"AIM-Harvard/reject_prompts\", \"train\"),\n",
    "                (\"jackhhao/jailbreak-classification\", \"test\"),\n",
    "                (\"sorry-bench/sorry-bench-202406\", \"train\"),\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"model_name\": \"google/gemma-2-9b-it\",\n",
    "            \"model_short\": \"gemma-2-9b-it\",\n",
    "            \"layers\": [\"9\", \"20\", \"31\"],\n",
    "            \"widths\": [\"16k\", \"131k\", \"1m\"],  # 2^14, 2^17, 2^20\n",
    "            \"datasets\": [\n",
    "                (\"Anthropic/election_questions\", \"test\"),\n",
    "                (\"textdetox/multilingual_toxicity_dataset\", \"en\"),\n",
    "                (\"AIM-Harvard/reject_prompts\", \"train\"),\n",
    "                (\"jackhhao/jailbreak-classification\", \"test\"),\n",
    "                (\"sorry-bench/sorry-bench-202406\", \"train\"),\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "def format_missing_files(missing_files: List[str]) -> str:\n",
    "    \"\"\"Format missing files in a structured hierarchy.\"\"\"\n",
    "    structure = defaultdict(\n",
    "        lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    )\n",
    "\n",
    "    for path in missing_files:\n",
    "        parts = Path(path).parts\n",
    "\n",
    "        # Extract components from path\n",
    "        for part in parts:\n",
    "            if part.startswith(\"gemma-\"):\n",
    "                model = part\n",
    "            elif part.startswith(\"width_\"):\n",
    "                width = part.replace(\"width_\", \"\")\n",
    "            elif any(\n",
    "                dataset in part\n",
    "                for dataset in [\n",
    "                    \"election_questions\",\n",
    "                    \"multilingual_toxicity_dataset\",\n",
    "                    \"reject_prompts\",\n",
    "                    \"jailbreak-classification\",\n",
    "                    \"sorry-bench\",\n",
    "                ]\n",
    "            ):\n",
    "                dataset = part\n",
    "            elif part in [\"train\", \"test\", \"en\"]:\n",
    "                split = part\n",
    "            elif part.startswith(\"layer_\"):\n",
    "                layer = part.replace(\"layer_\", \"\")\n",
    "\n",
    "        # Organize into nested structure\n",
    "        structure[model][width][f\"{dataset}/{split}\"][layer].append(path)\n",
    "\n",
    "    # Format the output\n",
    "    output = []\n",
    "    for model in sorted(structure.keys()):\n",
    "        output.append(f\"Model: {model}\")\n",
    "        for width in sorted(structure[model].keys()):\n",
    "            output.append(f\"  Width: {width}\")\n",
    "            for dataset in sorted(structure[model][width].keys()):\n",
    "                output.append(f\"    Task: {dataset}\")\n",
    "                for layer in sorted(structure[model][width][dataset].keys()):\n",
    "                    output.append(f\"      Layer: {layer}\")\n",
    "\n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "\n",
    "def verify_outputs(base_dir: str = \"./outputs\") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Verify that all expected output files exist.\n",
    "\n",
    "    Args:\n",
    "        base_dir: Base directory to look for outputs\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing lists of (found_files, missing_files)\n",
    "    \"\"\"\n",
    "    found_files = []\n",
    "    missing_files = []\n",
    "    configs = get_model_configs()\n",
    "\n",
    "    # Convert base_dir to absolute path\n",
    "    base_dir = os.path.abspath(base_dir)\n",
    "    print(f\"Checking files in: {base_dir}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    total_combinations = 0\n",
    "\n",
    "    for config in configs:\n",
    "        for width in config[\"widths\"]:\n",
    "            for layer in config[\"layers\"]:\n",
    "                for dataset, split in config[\"datasets\"]:\n",
    "                    total_combinations += 1\n",
    "                    # Convert dataset path to filesystem-friendly format\n",
    "                    dataset_path = dataset.replace(\"/\", \"_\")\n",
    "\n",
    "                    # Construct the expected path\n",
    "                    expected_path = os.path.join(\n",
    "                        base_dir,\n",
    "                        config[\"model_short\"],\n",
    "                        f\"width_{width}\",\n",
    "                        config[\"model_name\"].replace(\"/\", \"_\"),\n",
    "                        dataset_path,\n",
    "                        split,\n",
    "                        f\"layer_{layer}\",\n",
    "                        width,\n",
    "                        \"sample_0.npz\",\n",
    "                    )\n",
    "\n",
    "                    if os.path.exists(expected_path):\n",
    "                        found_files.append(expected_path)\n",
    "                    else:\n",
    "                        missing_files.append(expected_path)\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Total configurations to check: {total_combinations}\")\n",
    "    print(f\"Found: {len(found_files)}\")\n",
    "    print(f\"Missing: {len(missing_files)}\")\n",
    "\n",
    "    # Print missing files in structured format if any\n",
    "    if missing_files:\n",
    "        print(\"\\nMissing configurations:\")\n",
    "        print(format_missing_files(missing_files))\n",
    "\n",
    "    return found_files, missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking files in: /home/jg1223/sae_llava/src/outputs\n",
      "================================================================================\n",
      "\n",
      "Summary:\n",
      "Total configurations to check: 150\n",
      "Found: 91\n",
      "Missing: 59\n",
      "\n",
      "Missing configurations:\n",
      "Model: gemma-2-2b\n",
      "  Width: 1m\n",
      "    Task: AIM-Harvard_reject_prompts/train\n",
      "      Layer: 12\n",
      "      Layer: 19\n",
      "      Layer: 5\n",
      "    Task: Anthropic_election_questions/test\n",
      "      Layer: 12\n",
      "      Layer: 19\n",
      "      Layer: 5\n",
      "    Task: jackhhao_jailbreak-classification/test\n",
      "      Layer: 12\n",
      "      Layer: 19\n",
      "      Layer: 5\n",
      "    Task: sorry-bench_sorry-bench-202406/train\n",
      "      Layer: 12\n",
      "      Layer: 19\n",
      "      Layer: 5\n",
      "    Task: textdetox_multilingual_toxicity_dataset/en\n",
      "      Layer: 12\n",
      "      Layer: 19\n",
      "      Layer: 5\n",
      "Model: gemma-2-9b\n",
      "  Width: 131k\n",
      "    Task: jackhhao_jailbreak-classification/test\n",
      "      Layer: 31\n",
      "    Task: sorry-bench_sorry-bench-202406/train\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "  Width: 1m\n",
      "    Task: AIM-Harvard_reject_prompts/train\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "      Layer: 9\n",
      "    Task: Anthropic_election_questions/test\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "      Layer: 9\n",
      "    Task: jackhhao_jailbreak-classification/test\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "      Layer: 9\n",
      "    Task: sorry-bench_sorry-bench-202406/train\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "      Layer: 9\n",
      "    Task: textdetox_multilingual_toxicity_dataset/en\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "      Layer: 9\n",
      "Model: gemma-2-9b-it\n",
      "  Width: 131k\n",
      "    Task: AIM-Harvard_reject_prompts/train\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "      Layer: 9\n",
      "    Task: Anthropic_election_questions/test\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "      Layer: 9\n",
      "    Task: jackhhao_jailbreak-classification/test\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "      Layer: 9\n",
      "    Task: textdetox_multilingual_toxicity_dataset/en\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "  Width: 1m\n",
      "    Task: AIM-Harvard_reject_prompts/train\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "      Layer: 9\n",
      "    Task: Anthropic_election_questions/test\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "      Layer: 9\n",
      "    Task: jackhhao_jailbreak-classification/test\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "      Layer: 9\n",
      "    Task: sorry-bench_sorry-bench-202406/train\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "      Layer: 9\n",
      "    Task: textdetox_multilingual_toxicity_dataset/en\n",
      "      Layer: 20\n",
      "      Layer: 31\n",
      "      Layer: 9\n"
     ]
    }
   ],
   "source": [
    "found, missing = verify_outputs(\"./outputs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saefari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
