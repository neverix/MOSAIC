{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29be1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46621126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3cd2aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "class AttentionProbe2(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim: int, num_heads: int = 1, output_dim: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.query = nn.Parameter(\n",
    "            torch.randn(1, num_heads, 1, input_dim),\n",
    "        )\n",
    "        self.output = nn.Linear(input_dim * num_heads, output_dim)\n",
    "\n",
    "    def forward(self, x, _1=None, _2=None):\n",
    "        # x is of shape (batch_size, num_heads, seq_len, dim)\n",
    "        x = x[:, None].expand(-1, self.query.shape[1], -1, -1)\n",
    "        q = self.query.expand(x.shape[0], -1, -1, -1)\n",
    "\n",
    "        out = F.scaled_dot_product_attention(q, x, x)\n",
    "        out = rearrange(out, \"b h n d -> b (h n d)\")\n",
    "        return self.output(out)\n",
    "\n",
    "\n",
    "probe = AttentionProbe2(512, 1, 8)\n",
    "x = torch.randn(2, 10, 512)\n",
    "out = probe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd0d7ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "class AttentionProbe(nn.Module):\n",
    "    def __init__(self, d_in, n_heads, output_dim: int = 1, hidden_dim: int = 0):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(d_in, n_heads, bias=False)\n",
    "        self.v = nn.Linear(d_in, n_heads * (hidden_dim or output_dim))\n",
    "        self.n_heads = n_heads\n",
    "        self.output_dim = output_dim\n",
    "        self.position_weight = nn.Parameter(torch.zeros((n_heads,), dtype=torch.float32))\n",
    "        self.hidden_dim = hidden_dim\n",
    "        if hidden_dim:\n",
    "            self.o = nn.Linear(hidden_dim, output_dim)\n",
    "        self.attn_hook = nn.Identity()\n",
    "    def forward(self, x, mask, position):\n",
    "        k = self.q(x) - ((1 - mask.float()) * 1e9)[..., None] + position[..., None] * self.position_weight\n",
    "        p = torch.nn.functional.softmax(k, dim=-2)\n",
    "        self.attn_hook(p)\n",
    "        v = self.v(x).unflatten(-1, (self.n_heads, -1))\n",
    "        o = (p[..., None] * v).sum((-2, -3))\n",
    "        if self.hidden_dim:\n",
    "            o = self.o(o.relu())\n",
    "        return o\n",
    "\n",
    "probe = AttentionProbe(512, 8)\n",
    "x = torch.randn(2, 10, 512)\n",
    "mask = torch.randn(2, 10)\n",
    "position = torch.randn(2, 10)\n",
    "out = probe(x, mask, position)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00767d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing google-gemma-2-2b layer 19 16k with dataset Anthropic_election_questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 16k: 100%|██████████| 2000/2000 [00:05<00:00, 388.37it/s, loss=0.00508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.5000, Accuracy: 0.5161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 16k: 100%|██████████| 2000/2000 [00:05<00:00, 391.97it/s, loss=0.00653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9265, Accuracy: 0.8118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 16k: 100%|██████████| 2000/2000 [00:05<00:00, 397.46it/s, loss=0.00366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.5899, Accuracy: 0.5161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 16k: 100%|██████████| 2000/2000 [00:05<00:00, 393.43it/s, loss=0.00261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9881, Accuracy: 0.9081\n",
      "Mean ROC AUC: 0.7511 ± 0.2097\n",
      "Mean Accuracy: 0.6880 ± 0.1753\n",
      "Processing google-gemma-2-2b layer 19 65k with dataset Anthropic_election_questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 65k: 100%|██████████| 2000/2000 [00:05<00:00, 398.91it/s, loss=0.00884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.4948, Accuracy: 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 65k: 100%|██████████| 2000/2000 [00:05<00:00, 397.25it/s, loss=0.00563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9770, Accuracy: 0.9194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 65k: 100%|██████████| 2000/2000 [00:05<00:00, 399.11it/s, loss=0.00961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.5913, Accuracy: 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 65k: 100%|██████████| 2000/2000 [00:05<00:00, 377.35it/s, loss=0.0055] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.5000, Accuracy: 0.5189\n",
      "Mean ROC AUC: 0.6408 ± 0.1979\n",
      "Mean Accuracy: 0.6015 ± 0.1841\n",
      "Processing google-gemma-2-2b layer 12 16k with dataset Anthropic_election_questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 12 16k: 100%|██████████| 2000/2000 [00:05<00:00, 387.61it/s, loss=0.00856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9999, Accuracy: 0.9839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 12 16k: 100%|██████████| 2000/2000 [00:05<00:00, 386.17it/s, loss=0.0102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.3291, Accuracy: 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 12 16k: 100%|██████████| 2000/2000 [00:05<00:00, 384.06it/s, loss=0.00576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9979, Accuracy: 0.9892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 12 16k: 100%|██████████| 2000/2000 [00:05<00:00, 378.28it/s, loss=0.01]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9905, Accuracy: 0.7189\n",
      "Mean ROC AUC: 0.8293 ± 0.2889\n",
      "Mean Accuracy: 0.7940 ± 0.2098\n",
      "Processing google-gemma-2-2b layer 12 65k with dataset Anthropic_election_questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 12 65k: 100%|██████████| 2000/2000 [00:05<00:00, 370.64it/s, loss=0.0106] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9995, Accuracy: 0.9785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 12 65k: 100%|██████████| 2000/2000 [00:05<00:00, 394.74it/s, loss=0.00684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.6473, Accuracy: 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 12 65k: 100%|██████████| 2000/2000 [00:05<00:00, 386.66it/s, loss=0.0125] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9955, Accuracy: 0.9355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 12 65k: 100%|██████████| 2000/2000 [00:05<00:00, 394.03it/s, loss=0.00753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9945, Accuracy: 0.9568\n",
      "Mean ROC AUC: 0.9092 ± 0.1512\n",
      "Mean Accuracy: 0.8387 ± 0.2054\n",
      "Processing google-gemma-2-2b layer 5 16k with dataset Anthropic_election_questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 5 16k: 100%|██████████| 2000/2000 [00:05<00:00, 372.52it/s, loss=0.0167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9966, Accuracy: 0.9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 5 16k: 100%|██████████| 2000/2000 [00:05<00:00, 385.63it/s, loss=0.0265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9870, Accuracy: 0.9032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 5 16k: 100%|██████████| 2000/2000 [00:05<00:00, 399.90it/s, loss=0.0237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9947, Accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 5 16k: 100%|██████████| 2000/2000 [00:05<00:00, 380.02it/s, loss=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9937, Accuracy: 0.9568\n",
      "Mean ROC AUC: 0.9930 ± 0.0036\n",
      "Mean Accuracy: 0.9408 ± 0.0221\n",
      "Processing google-gemma-2-2b layer 5 65k with dataset Anthropic_election_questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 5 65k: 100%|██████████| 2000/2000 [00:05<00:00, 374.56it/s, loss=0.0174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9880, Accuracy: 0.5161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 5 65k: 100%|██████████| 2000/2000 [00:05<00:00, 391.94it/s, loss=0.0138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9867, Accuracy: 0.9247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 5 65k: 100%|██████████| 2000/2000 [00:05<00:00, 399.83it/s, loss=0.0221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9987, Accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 5 65k: 100%|██████████| 2000/2000 [00:05<00:00, 381.49it/s, loss=0.0175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9862, Accuracy: 0.8108\n",
      "Mean ROC AUC: 0.9899 ± 0.0051\n",
      "Mean Accuracy: 0.8022 ± 0.1738\n",
      "Processing google-gemma-2-2b layer 19 16k with dataset legacy-datasets_banking77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 16k: 100%|██████████| 2000/2000 [00:09<00:00, 208.94it/s, loss=0.142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 16k: 100%|██████████| 2000/2000 [00:09<00:00, 213.94it/s, loss=0.139] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 16k: 100%|██████████| 2000/2000 [00:09<00:00, 214.23it/s, loss=0.147] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 16k: 100%|██████████| 2000/2000 [00:09<00:00, 214.60it/s, loss=0.179] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3988\n",
      "Mean Accuracy: 0.2901 ± 0.1618\n",
      "Processing google-gemma-2-2b layer 19 65k with dataset legacy-datasets_banking77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 65k: 100%|██████████| 2000/2000 [00:09<00:00, 214.06it/s, loss=0.127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 65k: 100%|██████████| 2000/2000 [00:09<00:00, 214.94it/s, loss=0.138] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 65k: 100%|██████████| 2000/2000 [00:09<00:00, 215.02it/s, loss=0.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 19 65k: 100%|██████████| 2000/2000 [00:10<00:00, 197.46it/s, loss=0.167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3756\n",
      "Mean Accuracy: 0.3314 ± 0.1922\n",
      "Processing google-gemma-2-2b layer 12 16k with dataset legacy-datasets_banking77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 12 16k: 100%|██████████| 2000/2000 [00:09<00:00, 214.51it/s, loss=0.359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training google-gemma-2-2b 12 16k:   0%|          | 0/2000 [00:00<?, ?it/s, loss=5.44]"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import defaultdict, OrderedDict\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "import hashlib\n",
    "import joblib\n",
    "import re\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "cache_dir = Path(\"cache\")\n",
    "cache_dir.mkdir(exist_ok=True)\n",
    "output_path = Path(\"output\")\n",
    "train_iterations = 2000\n",
    "lr = 1e-4\n",
    "# wd = 1e-4\n",
    "wd = 0.0\n",
    "display_now = False\n",
    "# n_heads, last_only, take_mean, nonlinear = 1, False, False, False\n",
    "# n_heads, last_only, take_mean, nonlinear = 16, False, False, True\n",
    "n_heads, last_only, take_mean, nonlinear = 1, True, True, False\n",
    "batch_size = 256\n",
    "device = \"cuda:0\"\n",
    "seed = 4\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(device) if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer_names = {\n",
    "    \"google-gemma-2b\": \"google/gemma-2b\",\n",
    "    \"google-gemma-2-2b\": \"google/gemma-2-2b\",\n",
    "}\n",
    "for metadata_path in output_path.glob(\"**/*.csv\"):\n",
    "    config = dict(\n",
    "        train_iterations=train_iterations,\n",
    "        lr=lr,\n",
    "        wd=wd,\n",
    "        display_now=display_now,\n",
    "        n_heads=n_heads,\n",
    "        last_only=last_only,\n",
    "        take_mean=take_mean,\n",
    "        seed=seed,\n",
    "    )\n",
    "    key_encoded = hashlib.sha256((str(metadata_path) + str(config)).encode()).hexdigest()\n",
    "    cache_path = cache_dir / f\"{key_encoded}.pkl\"\n",
    "    if cache_path.exists():\n",
    "        continue\n",
    "    \n",
    "    dataset_path = metadata_path.parents[3].name\n",
    "    match = re.match(r\"([a-zA-Z0-9\\-]+)_([0-9]+)_activations_metadata\", metadata_path.stem)\n",
    "    if match is None:\n",
    "        print(\"Warning: No match found for\", metadata_path)\n",
    "        continue\n",
    "    model_name, layer_num = match.groups()\n",
    "    # if \"-2-\" in model_name:\n",
    "    #     continue\n",
    "    layer_num = int(layer_num)\n",
    "    sae_size = metadata_path.parents[0].name\n",
    "    print(f\"Processing {model_name} layer {layer_num} {sae_size} with dataset {dataset_path}\")\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "    metadata = metadata.drop_duplicates(subset=['npz_file'])\n",
    "    # Read all numpy files into an X array\n",
    "    numpys = [np.load(file) for file in metadata['npz_file']]\n",
    "    X = [npf['hidden_state'] for npf in numpys]\n",
    "    # input_ids = [npf['input_ids'][:len(x)] for npf, x in zip(numpys, X)]\n",
    "    input_ids = [npf['input_ids'] for npf, x in zip(numpys, X)]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_names[model_name])\n",
    "    hidden_dim = X[0].shape[-1]\n",
    "    max_seq_len = max([x.shape[0] for x in X])\n",
    "    # Pad sequences to the same length\n",
    "    X = dict(\n",
    "        x=np.array([np.pad(x, ((0, max_seq_len - x.shape[0]), (0, 0)), mode='constant', constant_values=0) for x in X]),\n",
    "        mask=np.array([np.pad(np.ones(x.shape[0]), (0, max_seq_len - x.shape[0]), mode='constant', constant_values=0) for x in X]),\n",
    "        position=np.array([np.pad(np.arange(x.shape[0]), (0, max_seq_len - x.shape[0]), mode='constant', constant_values=0) for x in X]),\n",
    "    )\n",
    "\n",
    "    # Turn labels from strings to ints\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(metadata['label'])\n",
    "    multi_class = len(np.unique(y)) > 2\n",
    "    # if not multi_class:\n",
    "    #     continue\n",
    "\n",
    "    # Create cross-validation splits\n",
    "    kf = StratifiedKFold(n_splits=4, shuffle=True, random_state=seed)\n",
    "    splits = list(kf.split(y, y))\n",
    "    \n",
    "    metrics = defaultdict(list)\n",
    "    for train, test in splits:\n",
    "        train_y, test_y = torch.tensor(y[train]).to(device), y[test]\n",
    "        train_x = {k: torch.tensor(v[train]).to(device) for k, v in X.items()}\n",
    "        test_x = {k: torch.tensor(v[test]).to(device) for k, v in X.items()}\n",
    "        \n",
    "        probe = AttentionProbe(hidden_dim, n_heads, hidden_dim=128 if nonlinear else 0, output_dim=1 if not multi_class else len(np.unique(y)))\n",
    "        probe = probe.to(device, torch.float32)\n",
    "        optimizer = torch.optim.AdamW(probe.parameters(), lr=lr, weight_decay=wd)\n",
    "        \n",
    "        for _ in (bar := trange(train_iterations, desc=f\"Training {model_name} {layer_num} {sae_size}\")):\n",
    "            optimizer.zero_grad()\n",
    "            indices = torch.randint(0, len(train_y), (batch_size,))\n",
    "            batch = {k: v[indices] for k, v in train_x.items()}\n",
    "            mask = batch['mask'].float()\n",
    "            position = batch['position']\n",
    "            if take_mean:\n",
    "                batch['x'] = batch['x'] * 0 + batch['x'].sum(-2, keepdim=True) / mask.sum(-1, keepdim=True)[..., None]\n",
    "            if last_only:\n",
    "                mask = mask * (position == position.max(axis=-1, keepdims=True).values)\n",
    "            with torch.autocast(device_type=device.type):\n",
    "                out = probe(batch['x'], mask, position)\n",
    "                if not multi_class:\n",
    "                    loss = F.binary_cross_entropy_with_logits(out, train_y[indices].float()[..., None])\n",
    "                else:\n",
    "                    loss = F.cross_entropy(out, train_y[indices])\n",
    "                loss.backward()\n",
    "            optimizer.step()\n",
    "            bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        with torch.inference_mode(), torch.autocast(device_type=device.type):\n",
    "            attns = []\n",
    "            probe.attn_hook.register_forward_hook(lambda _, __, output: attns.append(output.detach().cpu().numpy()))\n",
    "            out = probe(test_x['x'], test_x['mask'], test_x['position'])\n",
    "            if not multi_class:\n",
    "                probs = out.sigmoid().detach().cpu().numpy()[..., 0]\n",
    "            else:\n",
    "                probs = out.softmax(dim=-1).detach().cpu().numpy()\n",
    "            probe.attn_hook._foward_hooks = OrderedDict()\n",
    "            attns = np.concatenate(attns)\n",
    "        \n",
    "\n",
    "        htmls = []\n",
    "        for i in np.random.randint(0, len(attns), 5):\n",
    "            input_id, attn, label = input_ids[test[i]], attns[i], metadata[\"label\"].iloc[test[i]]\n",
    "            html = []\n",
    "            for i, (token_id, a) in enumerate(zip(input_id, attn)):\n",
    "                if token_id == tokenizer.eos_token_id or token_id == tokenizer.pad_token_id:\n",
    "                    continue\n",
    "                a = float(a[0])\n",
    "                s, f = 0.2, 0.9\n",
    "                a = min(1, s + f * a)\n",
    "                html.append(f\"<span style='color: rgba(1, 0, 0, {a:.2f})'>{tokenizer.decode(token_id)}</span>\")\n",
    "            html = f\"<div style='background-color: white; padding: 10px; color: black'>Class: {label} \" + \"\".join(html) + \"</div>\"\n",
    "            if display_now:\n",
    "                display(HTML(html))\n",
    "            htmls.append(html)\n",
    "        \n",
    "        if multi_class:\n",
    "            accuracy = accuracy_score(test_y, probs.argmax(axis=-1))\n",
    "        else:\n",
    "            accuracy = accuracy_score(test_y, probs > 0.5)\n",
    "        metrics['accuracy'].append(accuracy)\n",
    "        if not multi_class:\n",
    "            roc_auc = roc_auc_score(test_y, probs)\n",
    "            print(f\"ROC AUC: {roc_auc:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "            metrics['roc_auc'].append(roc_auc)\n",
    "        else:\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    if not multi_class:\n",
    "        roc_aucs = metrics['roc_auc']\n",
    "        print(f\"Mean ROC AUC: {np.mean(roc_aucs):.4f} ± {np.std(roc_aucs):.4f}\")\n",
    "    else:\n",
    "        roc_aucs = None\n",
    "    accuracies = metrics['accuracy']\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "    \n",
    "    result = dict(\n",
    "        data_info=dict(\n",
    "            metadata_path=metadata_path,\n",
    "            model_name=model_name,\n",
    "            layer_num=layer_num,\n",
    "            sae_size=sae_size,\n",
    "            dataset_path=dataset_path,\n",
    "        ),\n",
    "        eval_results=dict(\n",
    "            accuracies=accuracies,\n",
    "            roc_aucs=roc_aucs,\n",
    "        ),\n",
    "        htmls=htmls,\n",
    "        config=config\n",
    "    )\n",
    "    joblib.dump(result, cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f46b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for input_id, attn, label in zip(input_ids[:5], attns, metadata[\"label\"]):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
